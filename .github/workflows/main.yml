name: IP Data Daily Processor

on:
  workflow_dispatch:
    inputs:
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: 'false'
  schedule:
    - cron: '1 16 * * *'

permissions:
  contents: write

jobs:
  data-process:
    name: Process & Clean Data
    runs-on: ubuntu-latest
    env:
      DEBUG_MODE: ${{ github.event.inputs.debug_mode || 'false' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Generate Data File
        run: |
          pip install requests
          python main.py
          echo "ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨:"
          ls -l ISP_China*.dat
          # å°†æœ€æ–°æ–‡ä»¶å¤åˆ¶ä¸ºé™æ€åç§°
          cp ISP_China$(date +%Y-%m-%d).dat ISP_China_latest.dat

      - name: Intelligent File Cleanup
        id: cleanup
        shell: bash
        run: |
          if [ "$DEBUG_MODE" = "true" ]; then
            set -x
          fi

          cutoff_date_int=$(date -d "7 days ago" +%Y%m%d)
          echo "CUTOFF_DATE=${cutoff_date_int}" >> $GITHUB_ENV

          for file in ISP_China*.dat; do
            if [ -f "$file" ]; then
              date_part=$(echo "$file" | grep -Eo '[0-9]{4}-[0-9]{2}-[0-9]{2}' | head -1)
              if [ -n "$date_part" ]; then
                file_date_int=$(echo "$date_part" | tr -d '-')
                if [ "$file_date_int" -lt "$cutoff_date_int" ]; then
                  echo "ğŸš« åˆ é™¤è¿‡æœŸæ–‡ä»¶: ${file}"
                  rm -v "$file"
                fi
              fi
            fi
          done

          if [ -f ISP_China_latest.dat ]; then
            echo "âœ… ä¿ç•™æœ€æ–°æ–‡ä»¶: ISP_China_latest.dat"
          fi

      - name: Auto-Commit Changes
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: 'Automated Data Update'
          file_pattern: 'ISP_China*.dat'
